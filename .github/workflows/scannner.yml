name: Check for broken links
on: 
  workflow_dispatch: # allow manual trigger
  push:
    branches: 
      - main
  schedule:
    # run daily at 4 am
    # * is a special character in YAML so you have to quote this string
    - cron:  '0 4 * * *'
jobs:
  crawl_for_broken_links:
    runs-on: ubuntu-latest
    name: Broken-Links-Crawler
    steps:
    - name: Checking links
      uses: ScholliYT/Broken-Links-Crawler-Action@v3
      with:
        connect_limit_per_host: 1
        website_url: 'https://documentation.red-gate.com/'
        exclude_url_suffix: '.jar,.md5,.sha1,.pdf,.jpg,.gif,.png,.jpeg,.zip,.mp4,.webm,.svg,.docx,.xlsx,.pptx,.txt,.md,.json,.xml,.js,.css,/release-notes-and-other-versions'
        exclude_url_contained: 'dev.mysql.com,www.nuget.org,support.google.com,v1beta1.custom.metrics.k8s.io,mvnrepository.com,www.simple-talk.com,chocolatey.org,www.ericsink.com'
        verbose: 'true'
        max_retries: 2
        max_depth: 10